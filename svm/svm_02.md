SVM 算法让数学离我们不再那么绕远，SVM 正直让我们感觉到数学的重要性，也是我们实体产品技术人员能够理解的一个算法。所以我们认为 SVM 是一个很美算法，这种美是不言而喻，

这是一个带等式约束的优化问题，有目标值，有约束条件。那么想想假设没有约束条件这个问题是怎么求解的呢? 是不是直接 f对各个 x 求导等于 0,，解 x 就可以了，可以看到没有约束的话，求导为 0，那么各个 x 均为 0 吧，这样 f=0了，最小。但是x都为 0 不满足约束条件呀，那么问题就来了。这里在说一点的是，为什么上面说求导为 0 就可以呢? 理论上多数问题是可以的，但是有的问题不可以。如果求导为 0 一定可以的话，那么 f 一定是个凸优化问题，什么是凸的呢? 像下面这个左图： 

注意的是这个条件是对函数的任意 x 取值。如果满足第一个就是开口向上的凸，第二个是开口向下的凸。可以看到对于凸问题，你去求导的话，是不是只有一个极点，那么他就是最优点，很合理。类似的看看上图右边这个图，很明显这个条件对任意的x 取值不满足，有时满足第一个关系，有时满足第二个关系，对应上面的两处取法就是，所以这种问题就不行，再看看你去对它求导，会得到好几个极点。然而从图上可以看到，只有其中一个极点是最优解，其他的是局部最优解, 那么当真实问题的时候你选择那个? 说了半天要说啥呢, 就是拉格朗日法是一定适合于**凸问题**的, 不一定适合于其他问题, 还好我们最终的问题是凸问题。

回头再来看看有约束的问题, 既然有了**约束**不能直接求导, 那么如果把约束去掉不就可以了吗?怎么去掉呢? 这才需要拉格朗日方法。既然是等式约束, 那么我们把这个约束乘一个系数加到目标函数中去, 这样就相当于既考虑了原目标函数, 也考虑了约束条件，比如上面那个函数，加进去就变为:  

继续讨论关于带等式以及不等式的约束条件的凸函数优化。任何原始问题约束条件无非最多 3 种，等式约束，大于号约束，小于号约束，而这三种最终通过将约束方程化简化为两类：约束方程等于0和约束方程小于 0。再举个简单的方程为例，假设原始约束条件为下列所示： 
$$\min f(x) = x_1^2 -  2x_1 + 1 + x_2^2 + 4x_2 + 4$$
$$s.t. \begin{cases}
    x_1 + 10 x_2 > 10 \\
    10x_1 - 10x_2 < 10
\end{cases}$$

$$s.t. \begin{cases}
    10 - x_1 - 10 x_2 < 0 \\
    10x_1 - 10x_2  -10< 0
\end{cases}$$

为什么都变成等号与小于号，方便后面的，反正式子的关系没有发生任何变化就行了。
现在将约束拿到目标函数中去就变成：
$$$$
### 凸函数
#### 凸函数优化问题
#### 拉格朗日
#### 
可以用拉格朗日来解决约束条件问题，我们这里有多少个样本N就有多少
有些概念是我们需要

$$ G(x, r,\lambda) = f(x) + \sum_{i=1}^n \lambda_i f_i(x) + \sum_{j=1}^m r_j h_j(x)$$
$$ \lambda_i =  f_i(\lambda_i)$$
我们想象一下，可以将转换为关于$\lambda_i$的方程，其他都可以暂时看成参数，那么就是一个关于$\lambda_i$的线性方程，如下图，对函数求最小值就形成了一个凸函数，在凸函数上一定有一个最大值，因为
凹函数优化，有关凹函数优化问题，
$$ \lambda_1, \lambda_2$$
我们想象一下，分别在$x_0,x_1, \cdots x_n$ 在每一个点位置对应最小值如图
$$ min G(x, \mu \lambda) = min f(x)$$


约束条件g(x,y)是 2 维坐标上曲线，我们可想象这条曲线在 z 轴将限制曲线延伸成曲面会与曲面相交。
或者将曲面

支持向量机大多数人都认为是机器学习中最难于理解的，虽然难于理解但是其背后数学理论是很清晰的。这样我们在向客户解释我们是如何采用算法做出

### 几何意义
支持向量机评估标准，分割面向一侧分类点靠拢，知道通过一些点，这个线需要平移。那么这里平面为支撑平面，在2维为直线而在3为，那么如果两个平面达到最大值我们就说这个里，这隔离地带越宽也就是越好，这就是支持向量机几何意义。我们分隔平面位于两个支撑平面之间。
支持支持向量机，一般都都会经过一个支持一点，如果经过两个就是一种巧合。

我们用向量来表达直线
$$\vec{v} \cdot \vec{x} + b$$
有关内积介绍，几何意义为两个向量$\vec{a}$ 也就是$||a_1|||a_2||\cos \theta$ 也就是几何空间的知识。

### 推导支撑平面
w 平面的法向量也就是与分割平面垂直的向量，
$$\begin{aligned}
    w_0x_1 + b_1 = 0 \\
    w_0x_2 - b_2 = 0 
\end{aligned}$$

因为这两条直线具有相同斜率，
$$ \begin{aligned}
    wx+b = -1 \\
    wx+b = 1
\end{aligned} $$

$$ \begin{aligned}
    wx_1+b = -1 \\
    wx_2+b = 1
\end{aligned} $$

$$
    \begin{aligned}
        w \cdot (x_1 - x_2) = 2 \\
        ||w|| \cdot ||x_1 - x_2|| \cos \theta = 2 \\
        ||w|| \times d = 2 \\
        d = \frac{2}{||w||}
    \end{aligned}
$$

### 转化为凸优化问题
在许多书都有凸函数和凹函数来进行，所以有关凸函数和凹函数有必要给大家分享
- 凸函数
$$ \theta x_1 + (1 - \theta) x_2  $$
当满足
$$ f() $$
- 凹函数

$$
\begin{cases}
    w \cdot x_i + b \ge 1 & y_i = 1 \\
    w \cdot x_i + b \le 1 & y_i = -1 
\end{cases}
$$

$$ d = \frac{2}{||w||}$$

如果我们要数学上表示出这些表达式就有上面

$$\begin{aligned}
    \min_w \frac{||w||^2}{2} \\
    s.t. & y_i(w \cdot x_i + b) \ge 1, & i =1,2, \cdots , N 
\end{aligned}$$

### 凸优化问题
- 可以寻求凸优化
- 使用拉格朗日乘子算法
#### 什么是凸函数
$$f(x \theta + (1 - \theta)) y $$
$$y_i(wx_i + b) \ge 1$$
$$\min_w \frac{||w||^2}{w}$$

#### 拉格朗日乘子法
原理
$g(x,y)=c$
虚线可以看成等高线 ，等高线，极限值，一直扩展到就是我们需要，在几何上意义上相切的。红色向量刚好垂直向量，必须共线，



$$\begin{cases}
    \min f(x,y) \\
    g(x,y) = c
\end{cases}$$

$$L(x,y) = f(x,y) + \lambda (g(x,y) - c)$$
$$\nabla L = \nabla (f + \lambda (g-c))$$
$$\begin{aligned}
    \nabla L = \nabla (f + \lambda (g-c)) \\
    = \nabla f + \lambda \nabla g = 0 \\
    \nabla f = - \lambda \nabla g
\end{aligned}$$
KKT
继续讨论关于带等式以及不等式的约束条件的凸函数优化。任何原始问题约束条件无非最多3种，等式约束，大于号约束，小于号约束，而这三种最终通过将约束方程化简化为两类：约束方程等于0和约束方程小于0。再举个简单的方程为例，假设原始约束条件为下列所示： 
$$L(w,b,a) = \frac{1}{2} ||w||^2 - \sum_{i=1}^n \alpha_i(y_i(w^Tx_i + b) -1)$$


KKT 乘子法
$$\begin{cases}
    \frac{\partial L}{\partial w} \Rightarrow \sum_{i=1}^n \alpha_i y_i x_i \\
    \frac{\partial L}{\partial b} \Rightarrow \sum_{i=1}^n \alpha_i y_i = 0
\end{cases}$$
### 梯度
$$\nabla L(x,y) = (\frac{\partial L}{\partial x},\frac{\partial L}{\partial y})$$
