### 机器学习分类
- 无监督学习
### 问题
在超市的顾客，有客户关注产品品质，有的关注，客户有不同特征决定他们属于不同群体，我们只知道客户客户行为分析。
小朋友取动物园，小朋友没有专业知识，也会根据动物形象(特征)和动作(特征)来对动物进行分类。他们是根据经验以相似动物进行分类。
### 衡量相似的方法
答案是 **距离**,我们通过特性间距离来衡量相似程度。对于距离衡量，一般选用"明可夫斯基距离"(Minkowski Distance),简称 **明氏距离**

对于样本$x_i(x_{i1},x_{i2} \cdots x_{im})$以及$x_j(x_{j1},x_{j2} \cdots x_{jm})$
$$ d_{min}(x_i,x_j) = (\sum_{k=1}^m |x_{ik} - y_{jk}|^p)^{\frac{1}{p}} $$
实际上，**明氏距离** 可以
- 当 p=1 时，**明氏距离** 即 **曼哈顿距离**(Manhattan Distance)

$$ d_{min}(x_i,x_j) = (\sum_{k=1}^m |x_{ik} - y_{jk}|) $$

- 当 p=2 时，**明氏距离** 即 **欧式距离**(Euclidean Distance)
$$ d_{min}(x_i,x_j) = \sqrt{ \sum_{k=1}^m (x_{ik} - y_{jk})^2 }$$

我们更喜欢使用 **欧式距离**

- 当 $p= \infty$ 时，**明氏距离** 即 **切比雪夫距离**(Chebyshev Distance)

$$ d_{min}(x_i,x_j) = \lim_{p\rightarrow\infty}{ (\sum_{k=1}^m (x_{ik} - y_{jk})^p)^{\frac{1}{p}} } = \max_{k}(|x_{ik} - x_{jk}|)$$

### K-means 聚类算法
- 随机法，我们随机选取归类中心，然后进行按距离进行聚类，随后再更新中心点，通过不断迭代来找到稳定的中心点。
$$ u_i = \frac{1}{n_i} \sum_{reC_t} x$$

- 最远距离法

### 轮廓系数
我们希望每一个样本离其被分配到的簇尽可能地近，离其他的簇尽可能的远，对应样本点i的轮廓系数
$$ s(i) = \frac{b(i) - a(i)}{\max \{ b(i),a(i) \}} = \frac{\min \{ D_{iC_j}, j \neq i \} - D_{iC_i}}{ \max{\min\{ D_{iC_j, j \neq i}, D_{iC_i} \} } } $$
- a(i) 到同类点的距离取平均
- b(i) 计算点到不同类别点距离取平均值，然后在不同类别进行取最小值

假设 i 点被分为 A 类，我们希望 i 离 A 类其他点比较近，离其他类别（B类或C类）越远越好。轮廓系数等于 1 是我们理想

$$ S = \frac{1}{n} \sum_{i=1}^n s(i) $$

上述距离的计算公式一般使用欧式距离，轮廓系数的取值范围为[-1,1]，数值越接近于 1 说明模型分群效果越好。一般认为，当轮廓系数大于 0.5 时，模型分群效果好，当轮廓小于 0.2 时，模型分群效果不明显。

### 连续型数据标准化
在 K-means 算法中，我们使用距离衡量样本的远近，因此在距离的计算中，我们要保证每个变量对距离的权重都是一致的。但是当不同数量的变量放在一起时，数据量较大的变量对于距离产生更大的影响。
为了解决这个问题，我们进行聚类前对数据自动进行标准化处理。
$$ x_i = \frac{x_i - x_{min}}{ x_{max} - x_{min}} $$

### 分类型数据标准化
由于聚类的算法距离计算是面向数值变量的，因此当变量中包括分类型变量时，聚类算法不能直接处理，而要先对分类型变量进行数值处理

但是值得注意是，虽然采用哑变量的方法解决了分类变量的距离计算问题，但是通过哑变量进行计算将导致分类型变量的权重大于其他数值型变量。

$$ \sqrt{(1-0)^2 + (0-1)^2 + (0-0)} = \sqrt{2} =\approx 1.414$$

### 评估
对于 **无监督** 我们是如何评估，第一个难度是对 k 进行选择。
- 技术型方法
- 业务型方法

```python
# 这里使用鸢尾花数据集
iris = datasets.load_iris()
# 获取数据集
X = scale(iris.data)

y = pd.DataFrame(iris.target)
variable_names = iris.feature_names

print(X[0:10,])
```
```
[[-0.90068117  1.01900435 -1.34022653 -1.3154443 ]
 [-1.14301691 -0.13197948 -1.34022653 -1.3154443 ]
 [-1.38535265  0.32841405 -1.39706395 -1.3154443 ]
 [-1.50652052  0.09821729 -1.2833891  -1.3154443 ]
```

```
print(variable_names)
```
```
['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
```

![kmean](https://upload-images.jianshu.io/upload_images/8207483-0376e178740f60fe.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


```
              precision    recall  f1-score   support

           0       1.00      1.00      1.00        50
           1       0.74      0.78      0.76        50
           2       0.77      0.72      0.74        50

   micro avg       0.83      0.83      0.83       150
   macro avg       0.83      0.83      0.83       150
weighted avg       0.83      0.83      0.83       150
```