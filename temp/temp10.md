### 主题模型


想要了解隐含狄利克雷分布(Latent Dirichlet Allocation，以下简称LDA)模型我们需要对一下概念熟练掌握

#### 贝叶斯定理
贝叶斯模型遍布机器学习各个模型，还是先简单地回顾一下贝叶斯模型。贝叶斯模型是由 3 个部分组成
- 先验
- 后验
- 似然

这个很好理解，我们认识世界也是这个过程，根据自己从书本上学习到结合自己亲身经历就是我们对事物和世界的认知。贝叶斯就是将我们认知世界过程通过概率模型来描述出来。

还是投硬币示例来介绍我们认识投硬币这件事，我们在自己投硬币。根据经验认为投硬币正面和背面的概率各占一半都是 50% 概率，但是我们知己投硬币可能发现硬币正面朝上次数要大于背面朝上的次数。这样我们就需要调整参数

#### 二项分布与Beta

$$D(k|n,p) = \left( \begin{matrix}
    n\\
    k
\end{matrix} \right) p^k (1-p)^(n-k)$$
我们知道多次的 0 1 分布就是伯努利分布，这里 n 表示进行试验次数(也就是投掷硬币次数)而 k 表示我们期望事件出现次数(在投硬币试验中就是硬币正面朝上的次数) p 表示正面朝上的概率.

数据(似然)很好理解，但是对于先验分布，如何获得数据先验，通常我们会给出机会均等作为先验。因为希望这个先验分布和数据(似然)对应的二项分布集合后，得到的后验分布在后面还可以作为先验分布！就像上面例子里的“102个好人和101个的坏人”，它是前面一次贝叶斯推荐的后验分布，又是后一次贝叶斯推荐的先验分布。也即是说，我们希望先验分布和后验分布的形式应该是一样的，这样的分布我们一般叫共轭分布。在我们的例子里，我们希望找到和二项分布共轭的分布。

在这里说题外话，也是个人学习机器学习的一种方法，如果一个知识点对于你可能理解上有点困难，这时候我们就需要先混个脸熟，这个和追女孩是一样的。首先要经常见面

仔细观察Beta分布和二项分布，可以发现两者的密度函数很相似，区别仅仅在前面的归一化的阶乘项。那么它如何做到先验分布和后验分布的形式一样呢？后验分布 [公式] 推导如下：