### 机器学习中问题
机器学习中我们一切努力都是在根据已知找到一种关系，然后利用这个找到的关系来进行估计未知。这是我们经过一段学习后对机器学习的认识。这种关系就是函数，
### 函数
函数是一种关系，这种关系可以理解为数据间的映射，映射也就是一种关系
### 向量和矩阵
### 模
#### L_0
#### L_1(曼哈顿距离)
$$||X|| = |x_1| + |x_2| + \dots |x_n|$$
#### L_2(欧式距离)
$$||X||_2 = \sqrt{|x_1|^2 + |x_2|^2 + \dots |x_n|} $$

### 向量
我们需要知道向量用来表示每一个样本的特征向量，在机器学习中我们通常用大小字母表示矩阵而用小写的字母表示 x 样本，通过上标来表示第几个样本例如$x^{(i)}$ 表示第 i 个样本，而用下标表示 x 样本的第j个特性$x_j$，这里都是机器学习中经常出现的。


### 流形
流形学习的观点：认为我们所能观察到的数据实际上是由一个低维流行映射到高维空间的。由于数据内部特征的限制，一些高维中的数据会产生维度上的冗余，实际上这些数据只要比较低的维度就能唯一的表示。所以直观上来讲，一个流形好比是一个d维的空间，在一个m维的空间中（m>d）被扭曲之后的结果。需要注意的是流形并不是一个形状，而是一个空间。举个例子来说，比如说一块布，可以把它看成一个二维的平面，这是一个二维的空间，现在我们把它扭一扭（三维空间），它就变成了一个流形，当然不扭的时候，它也是一个流形，欧式空间是流形的一种特殊情况。如下图所示