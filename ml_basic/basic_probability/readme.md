在机器学习中有关贝叶斯概率即使不是最重要的,也算最重要之一了。我也是花费许多时间，经过似懂非懂才逐渐搞明白贝叶斯，大家如果想学习机器就得先熟练掌握贝叶斯理论，一定要做到张口就来，熟练掌握。

基础概念


#### 主观概率和客观概率
两个学派
是不同角度去解释概率，
有些事情是无法大量采样
不断测量对不确定性的度量这就是客观概率，

![conditional.jpg](https://upload-images.jianshu.io/upload_images/8207483-dbdfa23e87eb5fbe.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


#### 条件概率
条件概率是指事件A在事件B发生的条件下发生的概率。条件概率表示为：P（A|B）
$$P(AB) = P(A|B)P(B) \Rightarrow P(A|B) = \frac{P(AB)}{P(B)} $$


如何 A 和 B 是相互独立的那么所以 A和 B 概率是
$$P(AB) = P(A)P(B)$$
如果 A 和 B 不是相互独立情况下可以下层


#### 全概率公式
![Total-prob.png](https://upload-images.jianshu.io/upload_images/8207483-44bd7357a921abe9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
$$P(A) = \sum_{i=1}^N P(A|B_i)P(B_i)$$

基于条件概率和全概率公式，就可以得出贝叶斯概率

$$P(AB) = P(A|B)P(B)$$
$$P(BA) = P(B|A)P(A)$$

通过将上边两个方程联立，可以推导出方程

$$P(B|A)P(A) = P(A|B)P(B)$$

$$P(B|A) = \frac{P(A|B)P(B)}{P(A)}$$
$$P(B|A) = \frac{P(A|B)P(B)}{\sum_{i=1}^N P(A|B_i)P(B_i)}$$

#### 约翰的两个孩子的故事
1. 关键基于两个孩子，我有两个孩子，没有看到那个孩子有信息的
2. 关于第二孩子是没有信息
#### 二项分布(Binomial Probabilities)

$$p(k) = \left( \begin{matrix}
    k \\
    n
\end{matrix} \right)$$

#### 随机变量

#### 随机变量的期望和随机变量的函数
有关期望的概念，也是我们在学习之初一个比较 confusing 的概念，希望能够给大家将清楚，因为期望也是机器学习中一个比较重要的概念，其实并不难只要大家能够精确理解一下。期望其实就是算均值。

考虑每一个可能概率的均值,给定概率分布的均值就是期望。
掷骰子
|   | 1  | 2  | 3  | 4  | 5  | 6  |
|---|---|---|---|---|---|---|
| A  |  $\frac{1}{6}$ | $\frac{1}{6}$ | $\frac{1}{6}$ |$\frac{1}{6}$  | $\frac{1}{6}$ | $\frac{1}{6}$ |
| B  |  $\frac{1}{2}$ | $\frac{1}{10}$ | $\frac{1}{10}$ |$\frac{1}{10}$  | $\frac{1}{10}$ | $\frac{1}{10}$ |


$$E[x] = \sum_x xpx(x)$$


$$\frac{1}{N} \sum_x xp(x)$$

#### 函数期望
$$E[gx()]$$

#### 方差
$$var(X) = E[]$$
随机变量距离平均值的就是标准差，标准差的平方就是方差
#### 协方差
$$Cov(X,Y) = E(X-E(X))(Y-E(X))$$
$$$$

相关性

$$Cov(x,y) \approx 0$$

#### 联合概率分布
边缘分布，如果
#### 边缘概率
$$\sum_x P(x,y) = p(y)$$
$$\sum_y P(x,y) = p(x)$$

#### 概率密度函数
描述有些概率密度函数用于描述一些具体问题，概率分布
多大方差，均值和方差
##### 伯努利分布
$$f(k;p) = \begin{cases}
    p & if k = 1
\end{cases}$$

$$f(k;p) = p^k(1-p)^{1-k}$$
##### 二项式分布

##### 多项式分布
满足上面条件的概率
$$f(x_1,\dots) = \frac{\Gamma}{}$$

伽马函数是阶乘的扩展
今天理解了，

$$\Gamma(z+1) = z $$
$$\Gamma(n+1) = n \Gamma(n)$$
通过定义出不同指数分布
#### gamma 分布
#### Beta 分布
多样性，通过调整参数可以得到形状分布
#### 泊松分布
如果某事件以固定强度λ，随机且独立地出现，该事件在单位时间内出现的次数（个数）可以看成是服从泊松分布。

$$f(k;\lambda) = \frac{\lambda^k e^{-\lambda}}{k!}$$

百年不遇的美女，百年不遇美女也就是 100 年可能会出现一个这样美女那么，这样概率就可以用

#### 正态分布
$$f(x|\mu,\sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} e^{-\frac{(x - \mu)^2}{2 \sigma^2}}$$
均匀分布随机数
正态分布随机数

#### 对数正态分布

#### 指数分布
$$f(x; \lambda) = \begin{cases}
    \lambda e^{-\lambda x} & x \ge 0 \\
    0 & x < 0
\end{cases}$$

$$P(B) $$


$$$$
| 正面  | 背面  |
|---|---|
| H  | H  |
| H  | T  |

简化问题一个特殊硬币和普通硬币

| 正面  | 背面  |
|---|---|
| H  | H  |
| H  | T  |
2/3

| 正面  | 背面  |
|---|---|
| H  | H  |
| H  | T  |
| H  | T  |
2/4 2/4
| 正面  | 背面  |
|---|---|
| H  | H  |
| H  | T  |
| H  | T  |
| H  | T  |

3/5 2/5

2/101 99/101

2 贝叶斯
$$P(B|A) = P(A|B)P(B)/P(A)$$

$$P(C=S|H) = \frac{P(H|C=s)P(C=s)}{P(H)}$$

$$\begin{aligned}
    = \frac{1 * \frac{1}{100}}{\frac{101}{200}} \\
    = \frac{2}{101}
\end{aligned}$$

拿出硬币，这个硬币是普通硬币概率多大

有人说是门后面是车，或者是羊
| A  | B  | C |
|---|---|---|
|  $\frac{1}{3}$ |  $\frac{1}{3}$ | $\frac{1}{3}$  |
|   |  选择 | 开  |

P(A) = 1/3
P(C) = 2/3

简单的解释，


